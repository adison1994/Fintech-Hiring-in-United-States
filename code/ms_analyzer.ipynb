{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import re\n",
    "import csv\n",
    "\n",
    "driver = webdriver.Chrome('/Users/amivora/Downloads/chromedriver')\n",
    "target_url = 'https://ms.taleo.net/careersection/2/moresearch.ftl;jsessionid=4arnSxY8eNOOwoalVDMb6HPp4TBIYniVT83doaA4x_4pWQjKFxkl!-497835726'\n",
    "driver.get(target_url)\n",
    "\n",
    "jobs = []\n",
    "page = 0\n",
    "#head to first MS page\n",
    "driver.find_elements_by_id('requisitionListInterface.reqTitleLinkAction.row1')[0].click()\n",
    "index = 0\n",
    "for i in range(0,1000):\n",
    "    try: \n",
    "        jobdict = {}\n",
    "        job_title = driver.find_element_by_id('requisitionDescriptionInterface.reqTitleLinkAction.row1').text\n",
    "        job_number = driver.find_element_by_id('requisitionDescriptionInterface.reqContestNumberValue.row1').text\n",
    "        primary_location = driver.find_element_by_id('requisitionDescriptionInterface.ID1722.row1').text\n",
    "        job_type = driver.find_element_by_id('requisitionDescriptionInterface.ID1822.row1').text\n",
    "        description = re.sub('[^A-Za-z]+', ' ', driver.find_element_by_id('requisitionDescriptionInterface.ID1968.row1').text)\n",
    "        description += re.sub('[^A-Za-z]+', ' ',driver.find_element_by_id('requisitionDescriptionInterface.ID1999.row1').text)\n",
    "        description += re.sub('[^A-Za-z]+', ' ',driver.find_element_by_id('requisitionDescriptionInterface.ID2024.row1').text)\n",
    "        jobdict['Job Number'] = job_number\n",
    "        jobdict['Job Type'] = job_type\n",
    "        jobdict['url'] = target_url\n",
    "        jobdict['Job Title'] = job_title\n",
    "        jobdict['Job Responsibilities'] = description\n",
    "        jobdict['Location'] = primary_location\n",
    "        keys = jobdict.keys()\n",
    "        with open('../deliverables/ms_jobs.csv', 'a') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, keys)\n",
    "            if index == 0:\n",
    "                dict_writer.writeheader()\n",
    "            dict_writer.writerow(jobdict)\n",
    "        index = 1;\n",
    "    except:\n",
    "        pass\n",
    "    #move to next job\n",
    "    driver.find_element_by_id('requisitionDescriptionInterface.pagerDivID894.Next').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count Morgan Stanley\n",
    "import csv\n",
    "import re\n",
    "\n",
    "with open('../deliverables/Top100_WordCount.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    list_topWords=[]\n",
    "    for row in csv_reader:\n",
    "        list_topWords.append(row[1])\n",
    "        \n",
    "with open('../deliverables/ms_jobs.csv') as csv_file_msresults:\n",
    "    csv_reader_msresults = csv.reader(csv_file_msresults, delimiter=',')\n",
    "    top_words_lowercase=[]\n",
    "    for list_top_word in list_topWords:\n",
    "        top_words_lowercase.append(list_top_word.lower())\n",
    "        \n",
    "\n",
    "    csv_prep=[]\n",
    "    for job in csv_reader_msresults:\n",
    "        job_words=[]\n",
    "        for phrase in job:\n",
    "            for word in phrase.split(' '):\n",
    "                lWord=re.sub('[^A-Za-z]+', ' ', word.lower())\n",
    "                job_words.append(lWord)\n",
    "\n",
    "        jobId=job[0]\n",
    "        jobLink=job[2]\n",
    "        listId=1\n",
    "        csvRecord={}\n",
    "        csvRecord['jobNo'] = jobId\n",
    "        csvRecord['institution'] = \"Morgan Stanley\"\n",
    "        csvRecord['url'] = jobLink\n",
    "        csvRecord['listId'] = listId\n",
    "\n",
    "        list_freq={}\n",
    "        for index, top_word in enumerate(top_words_lowercase):\n",
    "                csvRecord[index]=job_words.count(top_word)\n",
    "\n",
    "        csv_prep.append(csvRecord)\n",
    "\n",
    "keys = csv_prep[0].keys()\n",
    "with open('../deliverables/ms_web_scraped_word_count.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(csv_prep)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text rank Morgan Stanley\n",
    "import csv\n",
    "import re\n",
    "\n",
    "with open('../deliverables/Top100_TextRank.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    list_topWords=[]\n",
    "    for row in csv_reader:\n",
    "        list_topWords.append(row[1])\n",
    "        \n",
    "with open('../deliverables/ms_jobs.csv') as csv_file_msresults:\n",
    "    csv_reader_msresults = csv.reader(csv_file_msresults, delimiter=',')\n",
    "    top_words_lowercase=[]\n",
    "    for list_top_word in list_topWords:\n",
    "        top_words_lowercase.append(list_top_word.lower())\n",
    "        \n",
    "\n",
    "    csv_prep=[]\n",
    "    for job in csv_reader_msresults:\n",
    "        job_words=[]\n",
    "        for phrase in job:\n",
    "            for word in phrase.split(' '):\n",
    "                lWord=re.sub('[^A-Za-z]+', ' ', word.lower())\n",
    "                job_words.append(lWord)\n",
    "\n",
    "        jobId=job[0]\n",
    "        jobLink=job[2]\n",
    "        listId=1\n",
    "        csvRecord={}\n",
    "        csvRecord['jobNo'] = jobId\n",
    "        csvRecord['institution'] = \"Morgan Stanley\"\n",
    "        csvRecord['url'] = jobLink\n",
    "        csvRecord['listId'] = listId\n",
    "\n",
    "        list_freq={}\n",
    "        for index, top_word in enumerate(top_words_lowercase):\n",
    "                csvRecord[index]=job_words.count(top_word)\n",
    "\n",
    "        csv_prep.append(csvRecord)\n",
    "\n",
    "keys = csv_prep[0].keys()\n",
    "with open('../deliverables/ms_web_scraped_text_rank.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(csv_prep)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TDIDF Morgan Stanley\n",
    "import csv\n",
    "import re\n",
    "\n",
    "with open('../deliverables/Top100_WordCountTFIDF.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    list_topWords=[]\n",
    "    for row in csv_reader:\n",
    "        list_topWords.append(row[1])\n",
    "        \n",
    "with open('../deliverables/ms_jobs.csv') as csv_file_msresults:\n",
    "    csv_reader_msresults = csv.reader(csv_file_msresults, delimiter=',')\n",
    "    top_words_lowercase=[]\n",
    "    for list_top_word in list_topWords:\n",
    "        top_words_lowercase.append(list_top_word.lower())\n",
    "        \n",
    "\n",
    "    csv_prep=[]\n",
    "    for job in csv_reader_msresults:\n",
    "        job_words=[]\n",
    "        for phrase in job:\n",
    "            for word in phrase.split(' '):\n",
    "                lWord=re.sub('[^A-Za-z]+', ' ', word.lower())\n",
    "                job_words.append(lWord)\n",
    "\n",
    "        jobId=job[0]\n",
    "        jobLink=job[2]\n",
    "        listId=1\n",
    "        csvRecord={}\n",
    "        csvRecord['jobNo'] = jobId\n",
    "        csvRecord['institution'] = \"Morgan Stanley\"\n",
    "        csvRecord['url'] = jobLink\n",
    "        csvRecord['listId'] = listId\n",
    "\n",
    "        list_freq={}\n",
    "        for index, top_word in enumerate(top_words_lowercase):\n",
    "                csvRecord[index]=job_words.count(top_word)\n",
    "\n",
    "        csv_prep.append(csvRecord)\n",
    "\n",
    "keys = csv_prep[0].keys()\n",
    "with open('../deliverables/ms_web_scraped_tfidf.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(csv_prep)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
